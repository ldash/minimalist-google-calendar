{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XiMB0iX8zyQKS6zQEs5dKIPVESaFDzR1",
      "authorship_tag": "ABX9TyNztdLPAB1utia6qBzHqFSD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldash/Minimalist-Google-Calendar/blob/master/WordCloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH5PS2iGmlwX",
        "outputId": "3d60b21a-4de4-407a-e246-79b096422688"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import requests\n",
        "import string\n",
        "\n",
        "from io import BytesIO\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "prefix = '/content/drive/MyDrive/Colab Notebooks/'\n",
        "\n",
        "def remove_chars_from_text(text, chars):\n",
        "    return ''.join([ch for ch in text if ch not in chars])\n",
        "\n",
        "\n",
        "def process(input_text):\n",
        "    input_text = remove_chars_from_text(input_text, string.punctuation + '\\xa0«»\\t—…')\n",
        "    input_text = remove_chars_from_text(input_text, string.digits)\n",
        "    text_tokens = word_tokenize(input_text)\n",
        "    russian_stopwords = stopwords.words('russian')\n",
        "    russian_stopwords.extend([\n",
        "        'alyona', 'bondarenko', 'lev', 'dashevskiy', 'media', 'omitted', 'deleted', 'message', 'check', 'add',\n",
        "        'favorites', 'mean', 'list', 'keep', 'top', 'picks', 'track', 'top', 'address', 'missed', 'voice', 'call',\n",
        "        'video', 'file', 'attached', 'live', 'location', 'payment', 'shared', 'hotel', 'home', 'wholesale',\n",
        "        'wishlist', 'linkedin', 'verification', 'started', 'smart', 'null', 'entrance', 'station', 'code', 'power',\n",
        "        'отличное', 'жилье', 'городе', 'улица', 'проспект',\n",
        "    ])\n",
        "    text_tokens = [\n",
        "        r for r in text_tokens if not (\n",
        "            r in russian_stopwords or\n",
        "            r.startswith('https') or\n",
        "            len(r) == 1\n",
        "        )\n",
        "    ]\n",
        "    return text_tokens\n",
        "\n",
        "\n",
        "# def clean(text_tokens_input):\n",
        "#     import pymorphy2\n",
        "#     morph = pymorphy2.MorphAnalyzer()\n",
        "#     text_tokens_norm = [morph.parse(r)[0].normal_form for r in text_tokens_input]\n",
        "#     return text_tokens_norm\n",
        "\n",
        "\n",
        "def form_matrix(img):\n",
        "    img_matrix = np.array(img)\n",
        "    img_matrix = img_matrix[:, :, img_matrix.shape[2]-1]\n",
        "    return np.invert(img_matrix)\n",
        "\n",
        "\n",
        "def read_img_from_url(url):\n",
        "    return Image.open(BytesIO(requests.get(url).content))\n",
        "\n",
        "\n",
        "def plot(key_input, tokens, bc, cw, cc, mask, invert, custom_ending=''):\n",
        "    file_name = key_input + '_' + bc\n",
        "    if invert:\n",
        "        mask = np.invert(mask)\n",
        "        file_name = file_name + '_inv'\n",
        "    if custom_ending:\n",
        "        file_name = file_name + '_' + custom_ending\n",
        "    svg = WordCloud(\n",
        "        random_state=0,\n",
        "        max_words=len(tokens),\n",
        "        mask=mask,\n",
        "        background_color=bc,\n",
        "        contour_width=cw,\n",
        "        contour_color=cc\n",
        "    ).generate(' '.join(tokens)).to_svg(embed_font=True)\n",
        "    with open(prefix + file_name + '.svg', 'w') as f:\n",
        "        f.write(svg)\n",
        "        print('Finished writing to: ' + prefix + file_name + '.svg')\n",
        "\n",
        "\n",
        "def adjust_sizes(img_url_l_input, img_url_a_input):\n",
        "    img_l_input = read_img_from_url(img_url_l_input)\n",
        "    img_a_input = read_img_from_url(img_url_a_input)\n",
        "    if img_l_input.size[1] > img_a_input.size[1]:\n",
        "        ratio = img_a_input.size[1] / float(img_l_input.size[1])\n",
        "        img_l_input = img_l_input.resize((int(img_l_input.size[0]*ratio), int(img_l_input.size[1]*ratio)))\n",
        "    else:  # img_a.size[1] > img_l.size[1]:\n",
        "        ratio = img_l_input.size[1] / float(img_a_input.size[1])\n",
        "        img_a_input = img_a_input.resize((int(img_a_input.size[0]*ratio), int(img_a_input.size[1]*ratio)))\n",
        "    return img_l_input, img_a_input\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    text = open(prefix + 'WhatsApp Chat with Alyona Bondarenko.txt', 'r', encoding='utf-8').read().lower()\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    raise e\n",
        "\n",
        "arr = text.split('\\n')\n",
        "l = [r for r in arr if \" - lev dashevskiy: \" in r]\n",
        "a = [r for r in arr if \" - alyona bondarenko: \" in r]\n",
        "d = {'comb': ' '.join(arr), 'l': ' '.join(l), 'a': ' '.join(a)}\n",
        "\n",
        "l_tokens = process(d['l'])\n",
        "a_tokens = process(d['a'])\n",
        "\n",
        "img_url_l = 'http://clipart-library.com/images_k/silhouette-of-man-head/silhouette-of-man-head-2.png'\n",
        "img_url_a = 'http://clipart-library.com/images_k/woman-silhouette-art/woman-silhouette-art-1.png'\n",
        "img_l, img_a = adjust_sizes(img_url_l, img_url_a)\n",
        "plot('l', l_tokens, 'aliceblue', 3, 'white', form_matrix(img_l), False, 'head')\n",
        "plot('a', a_tokens, 'mistyrose', 3, 'white', form_matrix(img_a), False, 'head')\n",
        "\n",
        "# img_url_l = 'http://clipart-library.com/images_k/silhouette-man-in-suit/silhouette-man-in-suit-20.png'\n",
        "# img_url_a = 'http://clipart-library.com/images_k/african-american-woman-silhouette/african-american-woman-silhouette-21.png'\n",
        "# img_l, img_a = adjust_sizes(img_url_l, img_url_a)\n",
        "# plot('l', l_tokens, 'aliceblue', 3, 'white', form_matrix(img_l), False, 'height')\n",
        "# plot('a', a_tokens, 'mistyrose', 3, 'white', form_matrix(img_a), False, 'height')\n",
        "# plot('l', l_tokens, 'aliceblue', 3, 'white', form_matrix(img_l), True, 'height')\n",
        "# plot('a', a_tokens, 'mistyrose', 3, 'white', form_matrix(img_a), True, 'height')\n",
        "\n",
        "\n",
        "key = 'comb'\n",
        "text_tokens_orig = process(d[key])\n",
        "\n",
        "full = read_img_from_url('http://clipart-library.com/images_k/black-heart-transparent-background/' +\n",
        "                          'black-heart-transparent-background-1.png')\n",
        "# broken = read_img_from_url('http://clipart-library.com/img/1087197.png')\n",
        "# broken = broken.resize((int(broken.size[0]*0.5), int(broken.size[1]*0.5)))\n",
        "\n",
        "# plot(key, text_tokens_orig, 'white', 0, '', form_matrix(full), False, 'full')\n",
        "# plot(key, text_tokens_orig, 'white', 0, '', form_matrix(full), True, 'full')\n",
        "plot(key, text_tokens_orig, 'black', 0, '', form_matrix(full), False, 'full')\n",
        "# plot(key, text_tokens_orig, 'black', 0, '', form_matrix(full), True, 'full')\n",
        "\n",
        "# plot(key, text_tokens_orig, 'white', 0, '', form_matrix(broken), False, 'broken')\n",
        "# plot(key, text_tokens_orig, 'black', 0, '', form_matrix(broken), False, 'broken')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished writing to: /content/drive/MyDrive/Colab Notebooks/l_aliceblue_head.svg\n",
            "Finished writing to: /content/drive/MyDrive/Colab Notebooks/a_mistyrose_head.svg\n",
            "Finished writing to: /content/drive/MyDrive/Colab Notebooks/comb_black_full.svg\n"
          ]
        }
      ]
    }
  ]
}